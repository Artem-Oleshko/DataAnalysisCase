{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dziVQ9sm6gn-"
   },
   "outputs": [],
   "source": [
    "!pip install pandas numpy matplotlib scikit-learn tensorflow keras\n",
    "!pip install human-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vUbVwUzSE26h"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Input, BatchNormalization, Flatten, Reshape\n",
    "from keras.callbacks import EarlyStopping\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wuwJMLh6SNHu"
   },
   "outputs": [],
   "source": [
    "#file_path = 'datasets/data_1.csv'\n",
    "file_path = 'datasets/data_2.xlsx'\n",
    "#data = pd.read_csv(file_path) \n",
    "data = pd.read_excel(file_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tHmnMEdSE6xP",
    "outputId": "44f54f3b-fb7e-48b2-a6b6-503d42e21de2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     int64\n",
       "First Name    object\n",
       "Last Name     object\n",
       "Gender        object\n",
       "Country       object\n",
       "Age            int64\n",
       "Date          object\n",
       "Id             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "5gzFOl74TdNr",
    "outputId": "03ed245e-db17-4873-f976-8d9748a24ab1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Date</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dulce</td>\n",
       "      <td>Abril</td>\n",
       "      <td>Female</td>\n",
       "      <td>United States</td>\n",
       "      <td>32</td>\n",
       "      <td>15/10/2017</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mara</td>\n",
       "      <td>Hashimoto</td>\n",
       "      <td>Female</td>\n",
       "      <td>Great Britain</td>\n",
       "      <td>25</td>\n",
       "      <td>16/08/2016</td>\n",
       "      <td>1582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Philip</td>\n",
       "      <td>Gent</td>\n",
       "      <td>Male</td>\n",
       "      <td>France</td>\n",
       "      <td>36</td>\n",
       "      <td>21/05/2015</td>\n",
       "      <td>2587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kathleen</td>\n",
       "      <td>Hanner</td>\n",
       "      <td>Female</td>\n",
       "      <td>United States</td>\n",
       "      <td>25</td>\n",
       "      <td>15/10/2017</td>\n",
       "      <td>3549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Nereida</td>\n",
       "      <td>Magwood</td>\n",
       "      <td>Female</td>\n",
       "      <td>United States</td>\n",
       "      <td>58</td>\n",
       "      <td>16/08/2016</td>\n",
       "      <td>2468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4996</td>\n",
       "      <td>Roma</td>\n",
       "      <td>Lafollette</td>\n",
       "      <td>Female</td>\n",
       "      <td>United States</td>\n",
       "      <td>34</td>\n",
       "      <td>15/10/2017</td>\n",
       "      <td>2654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4997</td>\n",
       "      <td>Felisa</td>\n",
       "      <td>Cail</td>\n",
       "      <td>Female</td>\n",
       "      <td>United States</td>\n",
       "      <td>28</td>\n",
       "      <td>16/08/2016</td>\n",
       "      <td>6525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4998</td>\n",
       "      <td>Demetria</td>\n",
       "      <td>Abbey</td>\n",
       "      <td>Female</td>\n",
       "      <td>United States</td>\n",
       "      <td>32</td>\n",
       "      <td>21/05/2015</td>\n",
       "      <td>3265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4999</td>\n",
       "      <td>Jeromy</td>\n",
       "      <td>Danz</td>\n",
       "      <td>Male</td>\n",
       "      <td>United States</td>\n",
       "      <td>39</td>\n",
       "      <td>15/10/2017</td>\n",
       "      <td>3265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>5000</td>\n",
       "      <td>Rasheeda</td>\n",
       "      <td>Alkire</td>\n",
       "      <td>Female</td>\n",
       "      <td>United States</td>\n",
       "      <td>29</td>\n",
       "      <td>16/08/2016</td>\n",
       "      <td>6125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 First Name   Last Name  Gender        Country  Age   \n",
       "0              1      Dulce       Abril  Female  United States   32  \\\n",
       "1              2       Mara   Hashimoto  Female  Great Britain   25   \n",
       "2              3     Philip        Gent    Male         France   36   \n",
       "3              4   Kathleen      Hanner  Female  United States   25   \n",
       "4              5    Nereida     Magwood  Female  United States   58   \n",
       "...          ...        ...         ...     ...            ...  ...   \n",
       "4995        4996       Roma  Lafollette  Female  United States   34   \n",
       "4996        4997     Felisa        Cail  Female  United States   28   \n",
       "4997        4998   Demetria       Abbey  Female  United States   32   \n",
       "4998        4999     Jeromy        Danz    Male  United States   39   \n",
       "4999        5000   Rasheeda      Alkire  Female  United States   29   \n",
       "\n",
       "            Date    Id  \n",
       "0     15/10/2017  1562  \n",
       "1     16/08/2016  1582  \n",
       "2     21/05/2015  2587  \n",
       "3     15/10/2017  3549  \n",
       "4     16/08/2016  2468  \n",
       "...          ...   ...  \n",
       "4995  15/10/2017  2654  \n",
       "4996  16/08/2016  6525  \n",
       "4997  21/05/2015  3265  \n",
       "4998  15/10/2017  3265  \n",
       "4999  16/08/2016  6125  \n",
       "\n",
       "[5000 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9cDkLP84f0_W"
   },
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "df['Country'] = df['Country'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fawSjFcxgAXe"
   },
   "outputs": [],
   "source": [
    "class Hash:\n",
    "\n",
    "    def __init__(self, str_object: str) -> None:\n",
    "        self.hash_value = 0\n",
    "        self.p = 31\n",
    "        self.m = 10**9 + 7\n",
    "        self.length = len(str_object)\n",
    "        hash_so_far = 0\n",
    "        p_pow = 1\n",
    "\n",
    "        for i in range(self.length):\n",
    "            hash_so_far = (hash_so_far + (1 + ord(str_object[i]) - ord('a')) * p_pow) % self.m\n",
    "            p_pow = (p_pow * self.p) % self.m\n",
    "            \n",
    "        self.hash_value = hash_so_far\n",
    "     \n",
    "    def __eq__(self, other) -> int:\n",
    "        return self.hash_value == other.hash_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OsX8yehNnxHn"
   },
   "outputs": [],
   "source": [
    "class DataTransform:\n",
    "\n",
    "    def __init__(self, data_frame: pd.core.frame.DataFrame, target_data: pd.core.series.Series):\n",
    "        self.count_categories = 30\n",
    "        self.one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.features = data.columns\n",
    "        self.features_types = {}\n",
    "        self.target = target_data\n",
    "        self.classes = {}\n",
    "        self.norm_target(self.target, data_frame)\n",
    "        self.transformed_data = pd.DataFrame()\n",
    "        self.arguable_type = 'object'\n",
    "        self.set_data_type(data_frame)\n",
    "        self.transform_object_series(data_frame)\n",
    "        self.transformed_data = self.transformed_data.drop([target_data.name], axis=1)\n",
    "\n",
    "    def hashing_object_series(self, data_series: pd.core.series.Series) -> pd.core.series.Series:\n",
    "        data_series = data_series.apply(lambda x: Hash(x).hash_value)\n",
    "        return data_series\n",
    "\n",
    "    def norm_target(self, data_series: pd.core.series.Series, data: pd.core.frame.DataFrame):\n",
    "        if self.check_categorical(data_series):\n",
    "            encoded_target = self.one_hot_encoder.fit_transform(data[[data_series.name]])\n",
    "            self.classes = dict(zip(self.target, encoded_target))\n",
    "            self.target = encoded_target\n",
    "            self.classes = {np.argmax(cat_array):label for label, cat_array in self.classes.items()}\n",
    "\n",
    "    def set_data_type(self, data: pd.core.frame.DataFrame) -> None:\n",
    "        self.features_types = {feature: self.check_type(data[feature]) for feature in self.features}  \n",
    "  \n",
    "    def check_categorical(self, data_series: pd.core.series.Series) -> bool:\n",
    "        categorical_cond = False\n",
    "        count_unique = data_series.nunique()\n",
    "        if count_unique/len(data_series) < self.count_categories/len(data_series):\n",
    "            categorical_cond = True\n",
    "        return categorical_cond\n",
    "\n",
    "    def check_type(self, data_series: pd.core.series.Series) -> str:\n",
    "    \n",
    "        str_data = []\n",
    "        int_data = []\n",
    "        float_data = []\n",
    "        #datetime_data = []\n",
    "        if data_series.dtypes == self.arguable_type:\n",
    "            \n",
    "            for el in data_series:\n",
    "                \n",
    "                if isinstance(el, str):\n",
    "                    \n",
    "                    str_data.append(el)\n",
    "                if isinstance(el, int):\n",
    "                    int_data.append(el)\n",
    "                if isinstance(el, float):\n",
    "                    float_data.append(el)\n",
    "            max_length = max(len(str_data), len(int_data), len(float_data))\n",
    "            if max_length == len(str_data):\n",
    "                series_type = 'object'\n",
    "            elif max_length == len(int_data):\n",
    "                series_type = 'int64'\n",
    "            else:\n",
    "                series_type = 'float64'\n",
    "        else:\n",
    "            series_type = data_series.dtype.name\n",
    "        return series_type   \n",
    "\n",
    "    def transform_object_series(self, data: pd.core.frame.DataFrame) -> None:\n",
    "   \n",
    "        for feature in self.features:\n",
    "            if 'date' in feature.lower():\n",
    "                self.transformed_data[feature] = pd.to_datetime(data[feature], format='%d/%m/%Y')\n",
    "            else:\n",
    "                if self.features_types[feature] == self.arguable_type:\n",
    "                    if not self.check_categorical(data[feature]):\n",
    "                        self.transformed_data[feature] = self.hashing_object_series(data[feature])\n",
    "                        self.transformed_data[feature] = self.transformed_data[feature]/self.transformed_data[feature].abs().max()\n",
    "                    else:\n",
    "                        self.label_encoder.fit(data[feature])\n",
    "                        self.transformed_data[feature] = self.label_encoder.transform(data[feature])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p1H9_bickVfQ",
    "outputId": "7f6f6afa-77ea-492b-e075-8e9ac5ad29db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Unnamed: 0': 'int64', 'First Name': 'object', 'Last Name': 'object', 'Gender': 'object', 'Country': 'object', 'Age': 'int64', 'Date': 'object', 'Id': 'int64'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{2: 'Female', 3: 'Male', 0: '34fd', 1: '3ew', 5: 'dfsve', 4: 'Nan'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transform = DataTransform(df, df['Gender'])\n",
    "\n",
    "print(df_transform.features_types)\n",
    "target_classes = df_transform.classes\n",
    "target_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "b38nVIvwj0wH",
    "outputId": "ed70bb07-6ceb-4d6d-cd54-4131e0d0b837"
   },
   "outputs": [],
   "source": [
    "X = df_transform.transformed_data.drop(['Date'], axis=1)\n",
    "y = df_transform.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num features: 3\n",
      "Num classes: 6\n"
     ]
    }
   ],
   "source": [
    "num_features = X.shape[1]\n",
    "num_classes = y.shape[1]\n",
    "print(f'Num features: {num_features}')\n",
    "print(f'Num classes: {num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0angy-wcW5bi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X data:\n",
      "       First Name  Last Name  Country\n",
      "0       0.004751   0.011436        3\n",
      "1       0.000047   0.312931        2\n",
      "2       0.469922   0.000613        1\n",
      "3       0.773831   0.523516        3\n",
      "4       0.010570   1.000000        3\n",
      "...          ...        ...      ...\n",
      "4995    0.000043   0.981280        3\n",
      "4996    0.046772   0.000368        3\n",
      "4997    0.034336   0.023379        3\n",
      "4998    0.733156   0.000793        3\n",
      "4999    0.212083   0.161015        3\n",
      "\n",
      "[5000 rows x 3 columns] \n",
      "y data:\n",
      " [[0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(f'X data:\\n {X} \\ny data:\\n {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 1, 3)              0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 512)               1056768   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16)               64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 6)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,233,046\n",
      "Trainable params: 1,232,502\n",
      "Non-trainable params: 544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(activation='relu', optimizer='adam'):\n",
    "    model = Sequential([\n",
    "        Reshape((1, num_features), input_shape=(num_features, )),\n",
    "        LSTM(512, return_sequences=False),\n",
    "        Flatten(),\n",
    "        Dense(256, activation=activation),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Dense(128, activation=activation),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation=activation),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation=activation),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation=activation),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "            ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model(activation='relu', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "36/36 [==============================] - 3s 14ms/step - loss: 1.9650 - accuracy: 0.3156\n",
      "Epoch 2/200\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 1.5950 - accuracy: 0.4607\n",
      "Epoch 3/200\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 1.2752 - accuracy: 0.5993\n",
      "Epoch 4/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 1.0088 - accuracy: 0.7209\n",
      "Epoch 5/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.8025 - accuracy: 0.7756\n",
      "Epoch 6/200\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 0.6866 - accuracy: 0.8004\n",
      "Epoch 7/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.5838 - accuracy: 0.8131\n",
      "Epoch 8/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.5390 - accuracy: 0.8202\n",
      "Epoch 9/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.5148 - accuracy: 0.8140\n",
      "Epoch 10/200\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 0.4656 - accuracy: 0.8269\n",
      "Epoch 11/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.4516 - accuracy: 0.8287\n",
      "Epoch 12/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.4357 - accuracy: 0.8302\n",
      "Epoch 13/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.4029 - accuracy: 0.8367\n",
      "Epoch 14/200\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 0.3903 - accuracy: 0.8436\n",
      "Epoch 15/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3771 - accuracy: 0.8438\n",
      "Epoch 16/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3845 - accuracy: 0.8429\n",
      "Epoch 17/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3948 - accuracy: 0.8396\n",
      "Epoch 18/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3349 - accuracy: 0.8589\n",
      "Epoch 19/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3358 - accuracy: 0.8598\n",
      "Epoch 20/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3383 - accuracy: 0.8656\n",
      "Epoch 21/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.3216 - accuracy: 0.8667\n",
      "Epoch 22/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3327 - accuracy: 0.8622\n",
      "Epoch 23/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3254 - accuracy: 0.8633\n",
      "Epoch 24/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3062 - accuracy: 0.8696\n",
      "Epoch 25/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.3039 - accuracy: 0.8693\n",
      "Epoch 26/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.2758 - accuracy: 0.8849\n",
      "Epoch 27/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.2801 - accuracy: 0.8811\n",
      "Epoch 28/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.2711 - accuracy: 0.8847\n",
      "Epoch 29/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3059 - accuracy: 0.8756\n",
      "Epoch 30/200\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.3302 - accuracy: 0.8651\n",
      "Epoch 31/200\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.3205 - accuracy: 0.8613\n"
     ]
    }
   ],
   "source": [
    "callback = EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=128, callbacks=[callback])\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2815310060977936\n",
      "Test accuracy: 90.39999842643738 %\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]}')\n",
    "print(f'Test accuracy: {score[1]*100} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 34fd can be Female\n",
      "Error: 3ew can be Female\n",
      "Error: dfsve can be Female\n",
      "Error: Nan can be Female\n",
      "Accuracy: 0.8994\n"
     ]
    }
   ],
   "source": [
    "ll = []\n",
    "non_ll = []\n",
    "pred_ll = []\n",
    "predict_1 = [np.argmax(pred) for pred in y_predict]\n",
    "for pred, test in zip(y_predict, y):\n",
    "    if np.argmax(pred) == np.argmax(test):\n",
    "        ll.append(1)\n",
    "    if np.argmax(test) not in predict_1:\n",
    "        print(f'Error: {target_classes[np.argmax(test)]} can be {target_classes[np.argmax(pred)]}')   \n",
    "print(f'Accuracy: {len(ll)/len(y_predict)}')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
